{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Processing Zooniverse Data Exports for Space Fluff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from datetime import date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_classify = '/home/anna/Desktop/SUNDIAL/images/beta_classify-classifications.csv'\n",
    "filename_onthego = '/home/anna/Desktop/SUNDIAL/images/beta_classify-on-the-go-classifications.csv'\n",
    "filename_hardcore = '/home/anna/Desktop/SUNDIAL/images/beta_classify-hardcore-edition-classifications.csv'\n",
    "\n",
    "\n",
    "outputfile_classify = '/home/anna/Desktop/SUNDIAL/images/beta_space-fluff_classifications_clean.csv'\n",
    "outputfile_onthego = '/home/anna/Desktop/SUNDIAL/images/beta_space-fluff_onthego_clean.csv'\n",
    "outputfile_hardcore = '/home/anna/Desktop/SUNDIAL/images/beta_space-fluff_hardcore_clean.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_out_classify = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_T0_classify', 'taskvalue_T1_classify', 'taskvalue_T2_classify',\n",
    "                'subject_name_classify']\n",
    "columns_out_onthego = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_T0_onthego', 'subject_name_onthego']\n",
    "\n",
    "# not all tasks are active in the hardcore workflow: amt there is T0, T2, T1, T3, T4, T5, T9 \n",
    "\n",
    "columns_out_hardcore = ['classification_id', 'created_at', 'user_name', 'user_id',\n",
    "               'workflow_id', 'workflow_version', 'subject_ids', \n",
    "               'taskvalue_T0', 'taskvalue_T1','taskvalue_T2', 'taskvalue_T3',\n",
    "                'taskvalue_T4', 'taskvalue_T5', 'taskvalue_T9', 'subject_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "columns_in = ['classification_id', 'user_name', 'user_id', 'user_ip', \n",
    "              'workflow_id','workflow_name', 'workflow_version', 'created_at', \n",
    "              'gold_standard', 'expert', 'metadata', 'annotations', \n",
    "              'subject_data', 'subject_ids']\n",
    "       \n",
    "columns_new_classify = ['metadata_json_classify', 'annotations_json_classify',\n",
    "                'subject_data_json_classify', \n",
    "               'taskvalue_T0_classify', 'taskvalue_T1_classify', 'taskvalue_T2_classify',\n",
    "                'subject_name_classify']\n",
    "columns_new_onthego = ['metadata_json_onthego', 'annotations_json_onthego',\n",
    "                'subject_data_json_onthego', \n",
    "               'taskvalue_T0_onthego', 'subject_name_onthego']\n",
    "columns_new_hardcore = ['metadata_json', 'annotations_json', 'subject_data_json', \n",
    "               'taskvalue_T0', 'taskvalue_T1','taskvalue_T2', 'taskvalue_T3',\n",
    "                'taskvalue_T4', 'taskvalue_T5', 'taskvalue_T9', 'subject_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_classify = pd.read_csv(filename_classify)\n",
    "classifications_classify = classifications_classify[6295:]\n",
    "\n",
    "classifications_onthego = pd.read_csv(filename_onthego)\n",
    "classifications_onthego = classifications_onthego[19989:]\n",
    "\n",
    "classifications_hardcore = pd.read_csv(filename_hardcore)\n",
    "classifications_hardcore = classifications_hardcore[5945:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_classify['metadata_json'] = [json.loads(q) for q in classifications_classify.metadata]\n",
    "classifications_classify['annotations_json'] = [json.loads(q) for q in classifications_classify.annotations]\n",
    "classifications_classify['subject_data_json'] = [json.loads(q) for q in classifications_classify.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_onthego['metadata_json'] = [json.loads(q) for q in classifications_onthego.metadata]\n",
    "classifications_onthego['annotations_json'] = [json.loads(q) for q in classifications_onthego.annotations]\n",
    "classifications_onthego['subject_data_json'] = [json.loads(q) for q in classifications_onthego.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifications_hardcore['metadata_json'] = [json.loads(q) for q in classifications_hardcore.metadata]\n",
    "classifications_hardcore['annotations_json'] = [json.loads(q) for q in classifications_hardcore.annotations]\n",
    "classifications_hardcore['subject_data_json'] = [json.loads(q) for q in classifications_hardcore.subject_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some functions to make things a bit cleaner\n",
    "\n",
    "def clean_answers_onthego(classifications, annotations_columns): \n",
    "    for i, row in classifications.iterrows():\n",
    "        answers = {'T0':''}\n",
    "        for t in row[annotations_columns]:\n",
    "            answers[t['task']] = t['value']\n",
    "        taskvalue_T0_onthego.append(answers['T0'])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "def clean_answers_classify(classifications, annotations_columns): \n",
    "    for i, row in classifications.iterrows():\n",
    "        answers = {'T0':'', 'T1':'', 'T2':''}\n",
    "        for t in row[annotations_columns]:\n",
    "            answers[t['task']] = t['value']\n",
    "        taskvalue_T0_classify.append(answers['T0'])\n",
    "        taskvalue_T1_classify.append(answers['T1'])\n",
    "        taskvalue_T2_classify.append(answers['T2'])\n",
    "\n",
    "    \n",
    "\n",
    "def clean_answers_hardcore(classifications, annotations_columns): \n",
    "    for i, row in classifications.iterrows():\n",
    "        answers = {'T0':'', 'T1':'', 'T2':'', 'T3':'', 'T4':'', 'T5':'', 'T9':''}\n",
    "        for t in row[annotations_columns]:\n",
    "            #print(t['task'],',  ',t['value'])\n",
    "            answers[t['task']] = t['value']\n",
    "        #print(answered)\n",
    "        taskvalue_T0.append(answers['T0'])\n",
    "        taskvalue_T1.append(answers['T1'])\n",
    "        taskvalue_T2.append(answers['T2'])\n",
    "        taskvalue_T3.append(answers['T3'])\n",
    "        taskvalue_T4.append(answers['T4'])\n",
    "        taskvalue_T5.append(answers['T5'])\n",
    "        taskvalue_T9.append(answers['T9'])\n",
    "         \n",
    "        #print('len of taskvalue: ', len(taskvalue_T0))\n",
    "\n",
    "def add_subject_name(classifications):\n",
    "    subject_name = []\n",
    "    for row in classifications['subject_data']:\n",
    "        image_no = row.split('IMAGE\":\"')[1]\n",
    "        subject_name.append(image_no.split('\"')[0])\n",
    "    #print('len of subj:  ',len(subject_name))    \n",
    "    return subject_name\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5945     Group of objects (Cluster)\n",
      "5946     Group of objects (Cluster)\n",
      "5947     Group of objects (Cluster)\n",
      "5948                         Galaxy\n",
      "5949                         Galaxy\n",
      "5950    Something else/empty center\n",
      "5951     Group of objects (Cluster)\n",
      "5952                         Galaxy\n",
      "5953                         Galaxy\n",
      "5954                         Galaxy\n",
      "5955                         Galaxy\n",
      "5956    Something else/empty center\n",
      "5957     Group of objects (Cluster)\n",
      "5958    Something else/empty center\n",
      "5959                         Galaxy\n",
      "5960     Group of objects (Cluster)\n",
      "5961     Group of objects (Cluster)\n",
      "5962    Something else/empty center\n",
      "5963    Something else/empty center\n",
      "5964    Something else/empty center\n",
      "Name: taskvalue_T0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "taskvalue_T0 = []\n",
    "taskvalue_T1 = []\n",
    "taskvalue_T2 = []\n",
    "taskvalue_T3 = []\n",
    "taskvalue_T4 = []\n",
    "taskvalue_T5 = []\n",
    "taskvalue_T9 = []\n",
    "\n",
    "\n",
    "clean_answers_hardcore(classifications_hardcore, 'annotations_json')\n",
    "subject_names = add_subject_name(classifications_hardcore)\n",
    "\n",
    "classifications_hardcore['taskvalue_T0'] = taskvalue_T0\n",
    "classifications_hardcore['taskvalue_T1'] = taskvalue_T1\n",
    "classifications_hardcore['taskvalue_T2'] = taskvalue_T2\n",
    "classifications_hardcore['taskvalue_T3'] = taskvalue_T3\n",
    "classifications_hardcore['taskvalue_T4'] = taskvalue_T4\n",
    "classifications_hardcore['taskvalue_T5'] = taskvalue_T5\n",
    "classifications_hardcore['taskvalue_T9'] = taskvalue_T9\n",
    "classifications_hardcore['subject_name'] = subject_names\n",
    "\n",
    "print(classifications_hardcore['taskvalue_T0'].head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskvalue_T0_onthego = []\n",
    "\n",
    "clean_answers_onthego(classifications_onthego, 'annotations_json')\n",
    "subject_names_onthego = add_subject_name(classifications_onthego)\n",
    "\n",
    "classifications_onthego['taskvalue_T0_onthego'] = taskvalue_T0_onthego\n",
    "classifications_onthego['subject_name_onthego'] = subject_names_onthego"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "taskvalue_T0_classify = []\n",
    "taskvalue_T1_classify = []\n",
    "taskvalue_T2_classify = []\n",
    "\n",
    "clean_answers_classify(classifications_classify, 'annotations_json')\n",
    "subject_names_classify = add_subject_name(classifications_classify)\n",
    "\n",
    "\n",
    "classifications_classify['taskvalue_T0_classify'] = taskvalue_T0_classify\n",
    "classifications_classify['taskvalue_T1_classify'] = taskvalue_T1_classify\n",
    "classifications_classify['taskvalue_T2_classify'] = taskvalue_T2_classify\n",
    "classifications_classify['subject_name_classify'] = subject_names_classify\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_hardcore = classifications_hardcore[columns_out_hardcore]\n",
    "output_hardcore.to_csv(outputfile_hardcore, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_classify = classifications_classify[columns_out_classify]\n",
    "output_classify.to_csv(outputfile_classify, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_onthego = classifications_onthego[columns_out_onthego]\n",
    "output_onthego.to_csv(outputfile_onthego, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
